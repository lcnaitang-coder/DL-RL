import sherpa_onnx
import numpy as np
import os

class SherpaKWSInterface:
    def __init__(self, num_classes=13, model_dir=None):
        self.num_classes = num_classes
        
        if model_dir is None:
            model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "kws_models")
        
        # é…ç½® Sherpa-onnx
        # è¯·ç¡®ä¿ kws_models ç›®å½•ä¸‹æœ‰ç›¸åº”çš„ onnx æ¨¡å‹æ–‡ä»¶
        config = sherpa_onnx.KeywordSpotterConfig(
            model=sherpa_onnx.OnlineModelConfig(
                transducer=sherpa_onnx.OnlineTransducerModelConfig(
                    encoder=f"{model_dir}/encoder-epoch-12-avg-2-chunk-16-left-64.onnx",
                    decoder=f"{model_dir}/decoder-epoch-12-avg-2-chunk-16-left-64.onnx",
                    joiner=f"{model_dir}/joiner-epoch-12-avg-2-chunk-16-left-64.onnx",
                ),
                tokens=f"{model_dir}/tokens.txt",
                num_threads=1,
            ),
            keywords_file=f"{model_dir}/keywords.txt",
        )
        self.spotter = sherpa_onnx.KeywordSpotter(config)
        self.stream = self.spotter.create_stream()
        
        # çŠ¶æ€å‘é‡ï¼š[13ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦, 1ä¸ªå…¨å±€é™éŸ³æ ‡å¿—]
        # ç»´åº¦ = 14
        self.current_state = np.zeros(num_classes + 1)
        self.decay_factor = 0.95 # ä¿¡å·è¡°å‡å› å­ï¼Œè®©è¯­éŸ³æŒ‡ä»¤åœ¨çŠ¶æ€ä¸­â€œå­˜æ´»â€ä¸€æ®µæ—¶é—´

        # å…³é”®è¯ ID æ˜ å°„è¡¨ (å¿…é¡»ä¸ keywords.txt ä¿æŒä¸€è‡´)
        self.keyword_map = {
            "å‘å‰": 0,
            "å‘ä¸Š": 1,
            "æ”¾å¼€": 2,
            "æä½": 3,
            "é¡ºæ—¶é’ˆ": 4,
            "é€†æ—¶é’ˆ": 5,
            "å‘å": 6,
            "å‘å³": 7,
            "ç¡®è®¤": 8,
            "é”å®š": 9,
            "å‘å·¦": 10,
            "ç‚¹èµ": 11,
            "å‘ä¸‹": 12
        }

    def process_audio_chunk(self, samples):
        """æ¥æ”¶éº¦å…‹é£æ•°æ®ï¼ˆfloat32 arrayï¼‰"""
        self.stream.accept_waveform(sample_rate=16000, waveform=samples)
        
        if self.spotter.is_ready(self.stream):
            self.spotter.decode(self.stream)
            result = self.spotter.get_result(self.stream)
            
            if result.keyword:
                # result.keyword è¿”å›çš„æ˜¯å…³é”®è¯æ–‡æœ¬
                # æ¯”å¦‚ "å‘å‰", "é”å®š" ç­‰
                detected_id = self._parse_keyword_id(result.keyword)
                
                # æ¿€æ´»å¯¹åº”çŠ¶æ€ï¼Œç½®ä¿¡åº¦è®¾ä¸º 1.0
                if 0 <= detected_id < self.num_classes:
                    self.current_state[detected_id] = 1.0
                    print(f"ğŸ¤ è¯­éŸ³æ£€æµ‹åˆ°: {result.keyword} (ID: {detected_id})")

    def get_state(self):
        """è¢« RL ç¯å¢ƒè°ƒç”¨ï¼Œè·å–å½“å‰è¯­éŸ³çŠ¶æ€"""
        # è¿”å›å½“å‰çŠ¶æ€çš„å‰¯æœ¬
        state = self.current_state.copy()
        
        # æ¯ä¸€å¸§è°ƒç”¨åï¼Œè®©ä¿¡å·è‡ªç„¶è¡°å‡
        # è¿™æ · RL å°±èƒ½çŸ¥é“ï¼šæ•°å€¼æ˜¯ 1.0 ä»£è¡¨åˆšè¯´å®Œï¼Œ0.5 ä»£è¡¨è¯´å®Œäº†ä¸€ä¼šå„¿
        self.current_state *= self.decay_factor 
        
        # å¦‚æœæ‰€æœ‰ä¿¡å·éƒ½å¾ˆå¼±ï¼Œè®¤ä¸ºå¤„äºé™éŸ³/å™ªå£°çŠ¶æ€
        if np.max(self.current_state[:-1]) < 0.1:
            self.current_state[-1] = 1.0 # æœ€åä¸€ä¸ªç»´åº¦è¡¨ç¤ºâ€œæ— è¯­éŸ³â€
        else:
            self.current_state[-1] = 0.0
            
        return state

    def _parse_keyword_id(self, keyword_str):
        # å¦‚æœ keyword_str åŒ…å« "@"ï¼Œå–å‰é¢éƒ¨åˆ† (è™½ç„¶ sherpa é€šå¸¸ç›´æ¥è¿”å›æ–‡æœ¬)
        if "@" in keyword_str:
            keyword_str = keyword_str.split("@")[1].split("/")[0] # ä¾‹å¦‚ "0@é”å®š/1.0" -> "é”å®š"
        
        # æœ‰æ—¶å€™ sherpa è¿”å›çš„ keyword å¸¦æœ‰ç©ºæ ¼ï¼Œéœ€è¦ strip
        clean_kw = keyword_str.strip()
        
        return self.keyword_map.get(clean_kw, -1)
